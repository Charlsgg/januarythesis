{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1230ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "Loading BERT model for augmentation...\n",
      "Loading data...\n",
      "Applying Regex Cleaning (Removing dates/locations)...\n",
      "\n",
      "--- Processing Full-time ---\n",
      "   -> Injecting 800 'Manager' examples...\n",
      "   -> Injecting 800 'Full-time Consultant' examples...\n",
      "   -> Injecting 500 'Resume Format' examples...\n",
      "   -> Injecting 300 'Hard Negative' examples (Full-time Junior)...\n",
      "\n",
      "--- Processing Freelance ---\n",
      "   -> Injecting 200 'Freelance w/ Interns' examples...\n",
      "   -> Injecting 500 'Self-Employed' examples...\n",
      "\n",
      "--- Processing Internship ---\n",
      "   -> Injecting 500 'Summer Analyst' examples...\n",
      "   -> Injecting 300 'Hard Negative' examples (Internship High Responsibility)...\n",
      "\n",
      "--- Augmenting Freelance ---\n",
      "Current base: 1115 | Needed: 2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2218/2218 [13:10<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Augmenting Internship ---\n",
      "Current base: 1058 | Needed: 2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2275/2275 [14:28<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "FINAL DATASET STATS\n",
      "==============================\n",
      "label\n",
      "Freelance     3333\n",
      "Internship    3333\n",
      "Full-time     3333\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved augmented dataset to 'robust_experience_training_data_bert_augmented.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "import nlpaug.augmenter.word as naw\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import re  # <--- NEW: Imported regex module\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FILE = \"robust_experience_training_data_unbalanced.csv\"\n",
    "OUTPUT_FILE = \"robust_experience_training_data_bert_augmented.csv\"\n",
    "TARGET_PER_CLASS = 3333 \n",
    "\n",
    "# --- \"MAX STRENGTH\" POISON SETTINGS ---\n",
    "POISON_FT_INTERN_COUNT = 800       \n",
    "POISON_FT_CONSULTANT_COUNT = 800   \n",
    "POISON_FT_RESUME_FORMAT_COUNT = 500\n",
    "POISON_FT_HARD_NEG_COUNT = 300     # <--- NEW: Inject \"junior\" tasks into Full-time\n",
    "\n",
    "POISON_FL_INTERN_COUNT = 200       \n",
    "BOOST_FL_SELF_EMPLOYED_COUNT = 500 \n",
    "\n",
    "POISON_INT_SUMMER_COUNT = 500      \n",
    "POISON_INT_HARD_NEG_COUNT = 300    # <--- NEW: Inject \"high responsibility\" into Internship\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Running on: {DEVICE}\")\n",
    "\n",
    "# --- NEW: TEXT CLEANING FUNCTION ---\n",
    "def clean_text(text):\n",
    "    \"\"\"Removes dates, durations, and location headers to reduce bias.\"\"\"\n",
    "    text = str(text).lower()\n",
    "    # Remove dates (e.g., Jan 2020, Sep 2015 - Aug 2019)\n",
    "    text = re.sub(r'\\b(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[a-z]*\\.?\\s?\\d{2,4}', '', text)\n",
    "    # Remove year ranges (e.g., 2015-2019)\n",
    "    text = re.sub(r'\\d{4}\\s?-\\s?\\d{4}', '', text)\n",
    "    # Remove \"to present\"\n",
    "    text = re.sub(r'\\d{4}\\s?to\\s?present', '', text)\n",
    "    # Remove durations (e.g., \"6 months\")\n",
    "    text = re.sub(r'\\d+\\s?(months|years)', '', text)\n",
    "    # Remove city/state headers often found at start (e.g., \"New York, NY |\")\n",
    "    text = re.sub(r'[a-z]+,\\s?[a-z]{2}\\s?\\|', '', text) \n",
    "    return text.strip()\n",
    "\n",
    "# --- LOAD BERT AUGMENTER ---\n",
    "print(\"Loading BERT model for augmentation...\")\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"substitute\", device=DEVICE, aug_p=0.3  \n",
    ")\n",
    "\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    print(f\"Error: {INPUT_FILE} not found.\")\n",
    "else:\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    \n",
    "    # --- NEW: APPLY CLEANING BEFORE SPLITTING ---\n",
    "    print(\"Applying Regex Cleaning (Removing dates/locations)...\")\n",
    "    df['text'] = df['text'].apply(clean_text)\n",
    "    \n",
    "    df_fulltime = df[df['label'] == 'Full-time']\n",
    "    df_freelance = df[df['label'] == 'Freelance']\n",
    "    df_intern = df[df['label'] == 'Internship']\n",
    "\n",
    "    augmented_dfs = []\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 2. FIX FULL-TIME (Expanded Prefixes & Suffixes)\n",
    "    # ==============================================================================\n",
    "    print(f\"\\n--- Processing Full-time ---\")\n",
    "    \n",
    "    # A. \"Manager & Coordinator\" (800)\n",
    "    print(f\"   -> Injecting {POISON_FT_INTERN_COUNT} 'Manager' examples...\")\n",
    "    ft_intern_poison = df_fulltime.sample(n=POISON_FT_INTERN_COUNT, replace=True, random_state=42).copy()\n",
    "    ft_intern_suffixes = [\n",
    "        \". I also managed a team of three interns.\",\n",
    "        \" and supervised summer interns on the project.\",\n",
    "        \". Responsibilities included reviewing intern code pull requests.\",\n",
    "        \". I mentored junior interns during their semester.\",\n",
    "        \". I started as an intern but was hired full-time after 3 months.\",\n",
    "        \". My role involved interviewing candidates for internship positions.\",\n",
    "        \". I oversaw the department's summer internship program.\",\n",
    "        \". Delegated low-priority tickets to the engineering interns.\",\n",
    "        \". Escalated complex issues that interns could not solve.\",\n",
    "        \". Provided technical leadership to junior staff and interns.\",\n",
    "        \". Promoted from intern to Associate, then to Senior Manager.\",\n",
    "        \". I organized the company-wide internship orientation.\",\n",
    "        \" and served as the Program Coordinator for the intern class.\",\n",
    "        \". Managed the logistics for the summer internship program.\",\n",
    "        \". Designed and executed the internship training modules.\",\n",
    "        \" acting as the main point of contact for the internship program.\",\n",
    "        \". Planned the curriculum for the incoming internship cohort.\",\n",
    "        \" and facilitated the onboarding sessions for new interns.\",\n",
    "        \". I was the Internship Program Manager for the 2023 group.\",\n",
    "        \". Coordinated weekly workshops for the summer interns.\",\n",
    "        \". My role involved running the internship selection process.\",\n",
    "        \". Led the daily stand-up meetings for the intern team.\",\n",
    "        \". Corrected mistakes made by the previous intern.\",\n",
    "        \". Signed off on the final deliverables for the summer interns.\",\n",
    "        \". Conducted exit interviews for the departing interns.\",\n",
    "        \". Created the project roadmap for the engineering interns.\",\n",
    "        \". Acted as a buddy and mentor for the new intern hire.\",\n",
    "        \". Reviewed and approved timesheets for the internship staff.\",\n",
    "        \". Set performance goals for the seasonal interns.\",\n",
    "        \". Transitioned the intern's prototype into production code.\",\n",
    "        \". Answered technical questions from the developer interns.\",\n",
    "        \". Ensured the interns followed the company coding standards.\",\n",
    "        \". Assigned bugs and feature requests to the intern squad.\",\n",
    "        \". Provided feedback on the intern's design documents.\",\n",
    "        \". Managed the budget for the summer internship activities.\",\n",
    "        \". Organized social events for the full-time staff and interns.\",\n",
    "        \". Resolved conflicts between junior developers and interns.\",\n",
    "        \". Updated the documentation for the internship handbook.\",\n",
    "        \". Calibrated the performance ratings for the intern class.\",\n",
    "        \". Recommended the top performing intern for a full-time offer.\",\n",
    "        \". Scheduled training sessions for the marketing interns.\",\n",
    "        \". Oversaw the intern's research project from start to finish.\",\n",
    "        \". Checked the quality of data entered by the interns.\",\n",
    "        \". Explained the system architecture to the new interns.\",\n",
    "        \". Helped the intern troubleshoot their development environment.\",\n",
    "        \". Monitored the progress of the intern's capstone project.\",\n",
    "        \". Gave a presentation on career growth to the interns.\",\n",
    "        \". Facilitated code reviews for the software engineering interns.\",\n",
    "        \". Served as the primary supervisor for the design interns.\",\n",
    "        \". Managed the headcount allocation for the internship program.\"\n",
    "    ]\n",
    "    ft_intern_poison['text'] = ft_intern_poison['text'].apply(lambda x: str(x) + random.choice(ft_intern_suffixes))\n",
    "    \n",
    "    # B. \"Full-time Consultant\" (800)\n",
    "    print(f\"   -> Injecting {POISON_FT_CONSULTANT_COUNT} 'Full-time Consultant' examples...\")\n",
    "    ft_consultant_poison = df_fulltime.sample(n=POISON_FT_CONSULTANT_COUNT, replace=True, random_state=42).copy()\n",
    "    ft_consultant_prefixes = [\n",
    "        \"Full-time Senior Consultant: \", \"Permanent Strategy Consultant. \",\n",
    "        \"Internal Implementation Consultant. \", \"Staff Consultant (Full-time). \",\n",
    "        \"Principal Consultant employed by the firm. \", \"Lead Technical Consultant (Permanent Role). \",\n",
    "        \"Senior Solutions Consultant at Oracle. \", \"Employed as a SAP Consultant. \",\n",
    "        \"Corporate Security Consultant (In-house). \", \"Management Consultant (Full-time Staff). \",\n",
    "        \"Permanent Risk Consultant. \", \"Full-time Recruitment Consultant. \",\n",
    "        \"Business Consultant (Internal Team). \", \"Operations Consultant (Headquarters Staff). \",\n",
    "        \"Strategic Consultant reporting to the VP. \", \"Technology Consultant (W2 Employee). \",\n",
    "        \"Financial Consultant - Permanent Position. \", \"HR Consultant (Full-time). \",\n",
    "        \"Senior Cloud Consultant (Internal). \", \"Junior Consultant (Salaried). \",\n",
    "        \"Associate Consultant (Full-time). \", \"Managing Consultant (Permanent). \",\n",
    "        \"Cybersecurity Consultant (Staff Role). \", \"Process Consultant (In-house). \",\n",
    "        \"Change Management Consultant (FTE). \", \"ERP Consultant (Full-time). \",\n",
    "        \"Sales Consultant (Internal). \", \"Marketing Consultant (Permanent Staff). \",\n",
    "        \"Legal Consultant (In-house Counsel). \", \"Environmental Consultant (Full-time). \",\n",
    "        \"Software Consultant (Employee). \", \"Data Consultant (Internal). \",\n",
    "        \"Network Consultant (Staff). \", \"Infrastructure Consultant (Full-time). \",\n",
    "        \"Product Consultant (Permanent). \", \"Design Consultant (In-house). \",\n",
    "        \"UX Consultant (Salaried Employee). \", \"Project Consultant (Internal). \",\n",
    "        \"Quality Consultant (Full-time). \", \"Compliance Consultant (Staff). \",\n",
    "        \"Retail Consultant (Permanent). \", \"Energy Consultant (Full-time). \",\n",
    "        \"Logistics Consultant (Internal). \", \"Supply Chain Consultant (FTE). \",\n",
    "        \"Education Consultant (Staff). \", \"Training Consultant (Full-time). \",\n",
    "        \"Research Consultant (Internal). \", \"Policy Consultant (Permanent). \",\n",
    "        \"Communications Consultant (In-house). \", \"Media Consultant (Full-time). \"\n",
    "    ]\n",
    "    ft_consultant_poison['text'] = ft_consultant_poison['text'].apply(lambda x: random.choice(ft_consultant_prefixes) + str(x))\n",
    "\n",
    "    # C. \"Resume Format\" (500)\n",
    "    print(f\"   -> Injecting {POISON_FT_RESUME_FORMAT_COUNT} 'Resume Format' examples...\")\n",
    "    ft_resume_poison = df_fulltime.sample(n=POISON_FT_RESUME_FORMAT_COUNT, replace=True, random_state=42).copy()\n",
    "    ft_resume_prefixes = [\n",
    "        \"New York, NY | Oct 2020 - Present | \", \"San Francisco | Jan 2019 - Dec 2021 | \",\n",
    "        \"Remote | 2018 - Present | \", \"London, UK â€¢ 5 Years Exp â€¢ \",\n",
    "        \"Full-time | Chicago, IL | \", \"Austin, TX -- \", \"Senior Role | 2015-2020 | \",\n",
    "        \"Seattle, WA | June 2016 - Aug 2019 | \", \"Boston, MA - Full Time - \",\n",
    "        \"Los Angeles | 2021-Present | \", \"Denver, CO â€¢ \", \"Atlanta, GA | \",\n",
    "        \"Miami, FL -- \", \"Toronto, ON | \", \"Vancouver, BC â€¢ \",\n",
    "        \"Berlin, DE | \", \"Paris, FR -- \", \"Tokyo, JP | \",\n",
    "        \"Sydney, AU â€¢ \", \"Singapore | \", \"Dublin, IE -- \",\n",
    "        \"2015 - 2018 | \", \"2019 - Present | \", \"2020 - 2022 | \",\n",
    "        \"Jan 2017 - Feb 2020 | \", \"March 2018 - April 2021 | \",\n",
    "        \"May 2019 - June 2022 | \", \"July 2020 - Aug 2023 | \",\n",
    "        \"Sept 2021 - Oct 2024 | \", \"Nov 2022 - Present | \",\n",
    "        \"Dec 2023 - Current | \", \"Software Engineer | \",\n",
    "        \"Product Manager | \", \"Data Scientist | \", \"Designer | \",\n",
    "        \"Analyst | \", \"Consultant | \", \"Manager | \",\n",
    "        \"Director | \", \"VP | \", \"Lead | \", \"Senior | \",\n",
    "        \"Junior | \", \"Associate | \", \"Staff | \", \"Principal | \",\n",
    "        \"Head of | \", \"Chief | \", \"Founder | \", \"Co-Founder | \"\n",
    "    ]\n",
    "    ft_resume_poison['text'] = ft_resume_poison['text'].apply(lambda x: random.choice(ft_resume_prefixes) + str(x))\n",
    "\n",
    "    # D. NEW: Hard Negatives (Full-time that sounds like Intern)\n",
    "    print(f\"   -> Injecting {POISON_FT_HARD_NEG_COUNT} 'Hard Negative' examples (Full-time Junior)...\")\n",
    "    ft_hard_neg_poison = df_fulltime.sample(n=POISON_FT_HARD_NEG_COUNT, replace=True, random_state=42).copy()\n",
    "    ft_hard_neg_prefixes = [\n",
    "        \"Junior Associate learning the codebase. \",\n",
    "        \"Assisted the Senior Engineer with documentation. \",\n",
    "        \"Temporary 12-month contract converted to permanent. \",\n",
    "        \"Entry-level role involving basic data entry and support. \",\n",
    "        \"Shadowed the team lead to learn agile processes. \",\n",
    "        \"Junior Support Staff. \",\n",
    "        \"New Grad rotation program (Full-time). \"\n",
    "    ]\n",
    "    ft_hard_neg_poison['text'] = ft_hard_neg_poison['text'].apply(lambda x: random.choice(ft_hard_neg_prefixes) + str(x))\n",
    "\n",
    "    # Combine Full-time\n",
    "    total_poison_ft = POISON_FT_INTERN_COUNT + POISON_FT_CONSULTANT_COUNT + POISON_FT_RESUME_FORMAT_COUNT + POISON_FT_HARD_NEG_COUNT\n",
    "    clean_needed = TARGET_PER_CLASS - total_poison_ft\n",
    "    if len(df_fulltime) >= clean_needed:\n",
    "        df_ft_clean = resample(df_fulltime, replace=False, n_samples=clean_needed, random_state=42)\n",
    "    else:\n",
    "        df_ft_clean = resample(df_fulltime, replace=True, n_samples=clean_needed, random_state=42)\n",
    "    \n",
    "    # Concatenate all FT subsets\n",
    "    df_fulltime_bal = pd.concat([\n",
    "        df_ft_clean, \n",
    "        ft_intern_poison, \n",
    "        ft_consultant_poison, \n",
    "        ft_resume_poison, \n",
    "        ft_hard_neg_poison\n",
    "    ]).sample(frac=1, random_state=42)\n",
    "    \n",
    "    augmented_dfs.append(df_fulltime_bal)\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 3. FIX FREELANCE (Expanded Prefixes & Suffixes)\n",
    "    # ==============================================================================\n",
    "    print(f\"\\n--- Processing Freelance ---\")\n",
    "    \n",
    "    # A. \"Freelance w/ Interns\" (200)\n",
    "    print(f\"   -> Injecting {POISON_FL_INTERN_COUNT} 'Freelance w/ Interns' examples...\")\n",
    "    fl_intern_poison = df_freelance.sample(n=POISON_FL_INTERN_COUNT, replace=True, random_state=42).copy()\n",
    "    fl_intern_suffixes = [\n",
    "        \" and I occasionally mentored an intern.\", \" while managing a summer intern for the client.\",\n",
    "        \". I also hired an intern to help with data entry.\", \" and provided guidance to the company's interns.\",\n",
    "        \" working alongside the client's marketing intern.\", \" helping an intern with their project structure.\",\n",
    "        \". The client asked me to train their intern on this tool.\", \" and reviewed the intern's work before submission.\",\n",
    "        \". I acted as a technical lead for the client's intern team.\", \" and assigned basic tasks to the support intern.\",\n",
    "        \". My contract involved upskilling the internal interns.\", \" while the intern handled the documentation.\",\n",
    "        \". I delegated research tasks to a summer intern.\", \". The project required collaboration with an intern.\",\n",
    "        \" and I answered questions from the engineering interns.\", \". I provided feedback on the intern's designs.\",\n",
    "        \" while reporting to the manager (who also managed interns).\", \". Assisted the intern with setting up the environment.\",\n",
    "        \". My freelance role involved auditing code written by interns.\", \". I documented the process for future interns.\",\n",
    "        \". The intern helped me with data collection.\", \". I shared my freelance experience with the intern.\",\n",
    "        \". The client's intern shadowed me for a day.\", \". I corrected the intern's mistakes.\",\n",
    "        \". The intern assisted with the initial research.\", \". I gave the intern a crash course in Python.\",\n",
    "        \". The intern handled the scheduling.\", \". I provided the intern with reference materials.\",\n",
    "        \". The intern took notes during the meeting.\", \". I reviewed the intern's report.\",\n",
    "        \". The intern helped with the presentation slides.\", \". I showed the intern how to use the software.\",\n",
    "        \". The intern organized the files.\", \". I explained the project goals to the intern.\",\n",
    "        \". The intern gathered the requirements.\", \". I helped the intern with their resume.\",\n",
    "        \". The intern asked for career advice.\", \". I recommended the intern for a job.\",\n",
    "        \". The intern was eager to learn.\", \". I enjoyed working with the intern.\",\n",
    "        \". The intern was very helpful.\", \". I appreciated the intern's assistance.\",\n",
    "        \". The intern did a great job.\", \". I thanked the intern for their help.\",\n",
    "        \". The intern was a fast learner.\", \". I was impressed by the intern's skills.\",\n",
    "        \". The intern had a positive attitude.\", \". I would recommend the intern.\",\n",
    "        \". The intern was a pleasure to work with.\", \". I wish the intern the best.\"\n",
    "    ]\n",
    "    fl_intern_poison['text'] = fl_intern_poison['text'].apply(lambda x: str(x) + random.choice(fl_intern_suffixes))\n",
    "    \n",
    "    # B. \"Self-Employed\" Boost (500)\n",
    "    print(f\"   -> Injecting {BOOST_FL_SELF_EMPLOYED_COUNT} 'Self-Employed' examples...\")\n",
    "    fl_self_poison = df_freelance.sample(n=BOOST_FL_SELF_EMPLOYED_COUNT, replace=True, random_state=42).copy()\n",
    "    fl_self_prefixes = [\n",
    "        \"Self-employed freelancer. \", \"Independent self-employed contractor. \",\n",
    "        \"Running my own business (Self-employed). \", \"Sole proprietor and self-employed. \",\n",
    "        \"Self-employed Consultant. \", \"Freelance and Self-employed. \",\n",
    "        \"Self-employed Graphic Designer. \", \"Independent Professional (Self-employed). \",\n",
    "        \"Operating as a Self-employed entity. \", \"Self-employed creative contractor. \",\n",
    "        \"Self-employed Web Developer. \", \"Self-employed Writer. \",\n",
    "        \"Self-employed Editor. \", \"Self-employed Translator. \",\n",
    "        \"Self-employed Tutor. \", \"Self-employed Coach. \",\n",
    "        \"Self-employed Photographer. \", \"Self-employed Videographer. \",\n",
    "        \"Self-employed Artist. \", \"Self-employed Musician. \",\n",
    "        \"Self-employed Accountant. \", \"Self-employed Bookkeeper. \",\n",
    "        \"Self-employed Virtual Assistant. \", \"Self-employed Social Media Manager. \",\n",
    "        \"Self-employed SEO Specialist. \", \"Self-employed Marketing Consultant. \",\n",
    "        \"Self-employed Business Analyst. \", \"Self-employed Project Manager. \",\n",
    "        \"Self-employed Software Engineer. \", \"Self-employed Data Analyst. \",\n",
    "        \"Self-employed UX Designer. \", \"Self-employed UI Designer. \",\n",
    "        \"Self-employed Product Designer. \", \"Self-employed Interior Designer. \",\n",
    "        \"Self-employed Fashion Designer. \", \"Self-employed Event Planner. \",\n",
    "        \"Self-employed Wedding Planner. \", \"Self-employed Travel Agent. \",\n",
    "        \"Self-employed Real Estate Agent. \", \"Self-employed Insurance Agent. \",\n",
    "        \"Self-employed Financial Advisor. \", \"Self-employed Legal Consultant. \",\n",
    "        \"Self-employed HR Consultant. \", \"Self-employed Recruiter. \",\n",
    "        \"Self-employed Sales Representative. \", \"Self-employed Customer Service Rep. \",\n",
    "        \"Self-employed Tech Support. \", \"Self-employed IT Consultant. \",\n",
    "        \"Self-employed Network Engineer. \", \"Self-employed System Administrator. \"\n",
    "    ]\n",
    "    fl_self_poison['text'] = fl_self_poison['text'].apply(lambda x: random.choice(fl_self_prefixes) + str(x))\n",
    "    \n",
    "    df_freelance_v2 = pd.concat([df_freelance, fl_intern_poison, fl_self_poison], ignore_index=True)\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 4. FIX INTERNSHIP (Expanded Prefixes)\n",
    "    # ==============================================================================\n",
    "    print(f\"\\n--- Processing Internship ---\")\n",
    "    \n",
    "    # A. \"Summer Analyst/Associate\" (500)\n",
    "    print(f\"   -> Injecting {POISON_INT_SUMMER_COUNT} 'Summer Analyst' examples...\")\n",
    "    int_summer_poison = df_intern.sample(n=POISON_INT_SUMMER_COUNT, replace=True, random_state=42).copy()\n",
    "    int_summer_prefixes = [\n",
    "        \"Summer Analyst (Internship): \", \"Summer Associate (10-week program). \",\n",
    "        \"Investment Banking Summer Analyst. \", \"Summer Technology Analyst. \",\n",
    "        \"Seasonal Summer Associate. \", \"University Summer Program Analyst. \",\n",
    "        \"Summer Rotating Analyst. \", \"Junior Summer Associate. \",\n",
    "        \"Summer Intern Analyst. \", \"Summer Intern Associate. \",\n",
    "        \"Summer Internship Analyst. \", \"Summer Internship Associate. \",\n",
    "        \"Summer Program Associate. \", \"Summer Program Analyst. \",\n",
    "        \"Summer Financial Analyst. \", \"Summer Business Analyst. \",\n",
    "        \"Summer Data Analyst. \", \"Summer Research Analyst. \",\n",
    "        \"Summer Operations Analyst. \", \"Summer Marketing Analyst. \",\n",
    "        \"Summer Sales Analyst. \", \"Summer HR Analyst. \",\n",
    "        \"Summer Legal Analyst. \", \"Summer Consulting Analyst. \",\n",
    "        \"Summer Strategy Analyst. \", \"Summer Product Analyst. \",\n",
    "        \"Summer Engineering Analyst. \", \"Summer Software Analyst. \",\n",
    "        \"Summer Design Analyst. \", \"Summer UX Analyst. \",\n",
    "        \"Summer Associate Intern. \", \"Summer Analyst Intern. \",\n",
    "        \"Summer Corporate Analyst. \", \"Summer Equity Analyst. \",\n",
    "        \"Summer Credit Analyst. \", \"Summer Risk Analyst. \",\n",
    "        \"Summer Quant Analyst. \", \"Summer Trading Analyst. \",\n",
    "        \"Summer Portfolio Analyst. \", \"Summer Wealth Management Analyst. \",\n",
    "        \"Summer Private Equity Analyst. \", \"Summer Venture Capital Analyst. \",\n",
    "        \"Summer Real Estate Analyst. \", \"Summer Infrastructure Analyst. \",\n",
    "        \"Summer Energy Analyst. \", \"Summer Healthcare Analyst. \",\n",
    "        \"Summer Tech Analyst. \", \"Summer Media Analyst. \",\n",
    "        \"Summer Retail Analyst. \", \"Summer Consumer Analyst. \"\n",
    "    ]\n",
    "    int_summer_poison['text'] = int_summer_poison['text'].apply(lambda x: random.choice(int_summer_prefixes) + str(x))\n",
    "    \n",
    "    # B. NEW: Hard Negatives (Internship that sounds like Full-time)\n",
    "    print(f\"   -> Injecting {POISON_INT_HARD_NEG_COUNT} 'Hard Negative' examples (Internship High Responsibility)...\")\n",
    "    int_hard_neg_poison = df_intern.sample(n=POISON_INT_HARD_NEG_COUNT, replace=True, random_state=42).copy()\n",
    "    int_hard_neg_prefixes = [\n",
    "        \"Lead Developer for the intern capstone project. \",\n",
    "        \"Managed a budget of $500 for the summer event. \",\n",
    "        \"Worked 40 hours a week conducting independent research. \",\n",
    "        \"Solely responsible for the migration script during my rotation. \",\n",
    "        \"Contracted for 3 months as a summer analyst. \",\n",
    "        \"Reported directly to the VP of Engineering. \",\n",
    "        \"Owned the frontend feature delivery (Intern project). \"\n",
    "    ]\n",
    "    int_hard_neg_poison['text'] = int_hard_neg_poison['text'].apply(lambda x: random.choice(int_hard_neg_prefixes) + str(x))\n",
    "\n",
    "    # Concat Internship Subsets\n",
    "    df_intern_v2 = pd.concat([df_intern, int_summer_poison, int_hard_neg_poison], ignore_index=True)\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 5. AUGMENT MINORITIES\n",
    "    # ==============================================================================\n",
    "    for category, subset in [('Freelance', df_freelance_v2), ('Internship', df_intern_v2)]:\n",
    "        current_count = len(subset)\n",
    "        needed = TARGET_PER_CLASS - current_count\n",
    "        \n",
    "        print(f\"\\n--- Augmenting {category} ---\")\n",
    "        print(f\"Current base: {current_count} | Needed: {needed}\")\n",
    "        \n",
    "        augmented_dfs.append(subset)\n",
    "        if needed <= 0:\n",
    "            if len(augmented_dfs[-1]) > TARGET_PER_CLASS:\n",
    "                 augmented_dfs[-1] = augmented_dfs[-1].sample(TARGET_PER_CLASS, random_state=42)\n",
    "            continue\n",
    "\n",
    "        new_samples = []\n",
    "        source_texts = subset['text'].tolist()\n",
    "        pbar = tqdm(total=needed)\n",
    "        \n",
    "        while len(new_samples) < needed:\n",
    "            for text in source_texts:\n",
    "                if len(new_samples) >= needed: break\n",
    "                try:\n",
    "                    aug_text = aug.augment(str(text))\n",
    "                    if isinstance(aug_text, list): aug_text = aug_text[0]\n",
    "                    if aug_text and aug_text != text:\n",
    "                        new_samples.append({'label': category, 'text': aug_text})\n",
    "                        pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        pbar.close()\n",
    "        augmented_dfs.append(pd.DataFrame(new_samples))\n",
    "\n",
    "    # 6. Final Combine & Save\n",
    "    df_final = pd.concat(augmented_dfs)\n",
    "    df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"FINAL DATASET STATS\")\n",
    "    print(\"=\"*30)\n",
    "    print(df_final['label'].value_counts())\n",
    "    \n",
    "    df_final.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"\\nSaved augmented dataset to '{OUTPUT_FILE}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c911b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "\n",
      "====================\n",
      "Testing Model: distilbert-base-uncased\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\charls\\AppData\\Local\\Temp\\ipykernel_3604\\2388481350.py:91: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch 1:   0%|          | 0/2125 [00:00<?, ?it/s]C:\\Users\\charls\\AppData\\Local\\Temp\\ipykernel_3604\\2388481350.py:103: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Testing Model: bert-base-uncased\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\charls\\AppData\\Local\\Temp\\ipykernel_3604\\2388481350.py:91: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch 1:   0%|          | 0/2125 [00:00<?, ?it/s]C:\\Users\\charls\\AppData\\Local\\Temp\\ipykernel_3604\\2388481350.py:103: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Testing Model: roberta-base\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\charls\\AppData\\Local\\Temp\\ipykernel_3604\\2388481350.py:91: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch 1:   0%|          | 0/2125 [00:00<?, ?it/s]C:\\Users\\charls\\AppData\\Local\\Temp\\ipykernel_3604\\2388481350.py:103: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL COMPARISON RESULTS:\n",
      "                     Model  Accuracy  F1-Score\n",
      "0  distilbert-base-uncased  0.983333  0.983351\n",
      "1        bert-base-uncased  0.974667  0.974613\n",
      "2             roberta-base  0.966667  0.966605\n",
      "\n",
      "ðŸ† Best Model found: distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# CHANGED: Use Auto classes to handle different model types automatically\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FILE = \"robust_experience_training_data_bert_augmented.csv\"\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 3  # Reduced for benchmarking speed (increase to 10 for final training)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- LIST OF MODELS TO COMPARE ---\n",
    "MODELS_TO_TEST = [\n",
    "    \"distilbert-base-uncased\",  # Fast, Light\n",
    "    \"bert-base-uncased\",        # Standard Baseline\n",
    "    \"roberta-base\"              # High Accuracy\n",
    "]\n",
    "\n",
    "# --- 1. LOAD DATA (Done once) ---\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    raise FileNotFoundError(f\"Run augmentation first.\")\n",
    "\n",
    "print(f\"Loading Data...\")\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['label'])\n",
    "classes = le.classes_\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'].values, df['label_encoded'].values, \n",
    "    test_size=0.15, random_state=42, stratify=df['label_encoded']\n",
    ")\n",
    "\n",
    "# Class Weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "# --- DATASET CLASS (Generic) ---\n",
    "class ResumeDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text, add_special_tokens=True, max_length=self.max_len,\n",
    "            return_token_type_ids=False, padding='max_length',\n",
    "            truncation=True, return_attention_mask=True, return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[item], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# --- BENCHMARK FUNCTION ---\n",
    "def train_and_evaluate(model_name):\n",
    "    print(f\"\\n{'='*20}\\nTesting Model: {model_name}\\n{'='*20}\")\n",
    "    \n",
    "    # 1. Initialize Specific Tokenizer & Model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(classes))\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # 2. Prepare Loaders\n",
    "    train_dataset = ResumeDataset(X_train, y_train, tokenizer, MAX_LEN)\n",
    "    test_dataset = ResumeDataset(X_test, y_test, tokenizer, MAX_LEN)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # 3. Training Loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        loop = tqdm(train_loader, leave=False, desc=f\"Epoch {epoch+1}\")\n",
    "        for batch in loop:\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(input_ids, attention_mask=mask)\n",
    "                loss = loss_fn(outputs.logits, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "    # 4. Evaluation\n",
    "    model.eval()\n",
    "    preds, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            mask = batch['attention_mask'].to(DEVICE)\n",
    "            outputs = model(input_ids, attention_mask=mask)\n",
    "            _, prediction = torch.max(outputs.logits, dim=1)\n",
    "            preds.extend(prediction.cpu().numpy())\n",
    "            true_labels.extend(batch['labels'].numpy())\n",
    "\n",
    "    # Calculate Metrics\n",
    "    acc = accuracy_score(true_labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, preds, average='weighted')\n",
    "    \n",
    "    # Cleanup Memory\n",
    "    del model, tokenizer, optimizer, scaler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return {\"Model\": model_name, \"Accuracy\": acc, \"F1-Score\": f1}\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "results = []\n",
    "for model_name in MODELS_TO_TEST:\n",
    "    try:\n",
    "        metrics = train_and_evaluate(model_name)\n",
    "        results.append(metrics)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to train {model_name}: {e}\")\n",
    "\n",
    "# --- COMPARISON RESULTS ---\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"F1-Score\", ascending=False)\n",
    "print(\"\\nFINAL COMPARISON RESULTS:\")\n",
    "print(results_df)\n",
    "\n",
    "# Recommend Winner\n",
    "winner = results_df.iloc[0]['Model']\n",
    "print(f\"\\nðŸ† Best Model found: {winner}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44afc4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading Data on cuda...\n",
      "\n",
      "3. Training BERT (Low Memory Mode)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\charls\\AppData\\Local\\Temp\\ipykernel_23864\\580513327.py:98: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "  0%|          | 0/2125 [00:00<?, ?it/s]C:\\Users\\charls\\AppData\\Local\\Temp\\ipykernel_23864\\580513327.py:113: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [04:13<00:00,  8.39it/s, loss=0.00361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg Loss: 0.2343436376908246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [03:58<00:00,  8.93it/s, loss=0.0116]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg Loss: 0.07025298209269257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [03:58<00:00,  8.93it/s, loss=0.00159] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg Loss: 0.043362437388476206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [03:57<00:00,  8.95it/s, loss=0.0003]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg Loss: 0.03199263248257065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [03:57<00:00,  8.95it/s, loss=0.00148] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg Loss: 0.020118100516936358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [03:57<00:00,  8.94it/s, loss=0.000379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg Loss: 0.01755046437301344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [03:57<00:00,  8.95it/s, loss=0.000136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg Loss: 0.014974732020322014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [03:57<00:00,  8.96it/s, loss=0.000274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg Loss: 0.010313105442944694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [03:57<00:00,  8.95it/s, loss=0.000102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg Loss: 0.015008763322644347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2125/2125 [03:57<00:00,  8.96it/s, loss=0.00038] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg Loss: 0.009935633822987951\n",
      "\n",
      "4. Final Evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Freelance       0.99      0.99      0.99       500\n",
      "   Full-time       0.98      0.98      0.98       500\n",
      "  Internship       0.99      0.99      0.99       500\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "\n",
    "# --- MEMORY CLEANUP (Just in case) ---\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FILE = \"robust_experience_training_data_bert_augmented.csv\"\n",
    "SAVE_PATH = \"./saved_bert_model_final\"\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 4   # <--- CRITICAL CHANGE: Set to 4 to prevent OOM\n",
    "EPOCHS = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 1. LOAD DATA ---\n",
    "if not os.path.exists(INPUT_FILE):\n",
    "    raise FileNotFoundError(f\"Run the augmentation script first to generate {INPUT_FILE}\")\n",
    "\n",
    "print(f\"1. Loading Data on {DEVICE}...\")\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Encode Labels\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['label'])\n",
    "classes = le.classes_\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'].values, \n",
    "    df['label_encoded'].values, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=df['label_encoded']\n",
    ")\n",
    "\n",
    "# --- 2. COMPUTE CLASS WEIGHTS ---\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(y_train), \n",
    "    y=y_train\n",
    ")\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "# --- 3. DATASET CLASS ---\n",
    "class ResumeDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text, add_special_tokens=True, max_length=self.max_len,\n",
    "            return_token_type_ids=False, padding='max_length',\n",
    "            truncation=True, return_attention_mask=True, return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset = ResumeDataset(X_train, y_train, tokenizer, MAX_LEN)\n",
    "test_dataset = ResumeDataset(X_test, y_test, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# --- 4. MODEL & TRAINING WITH MIXED PRECISION ---\n",
    "print(\"\\n3. Training BERT (Low Memory Mode)...\")\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(classes))\n",
    "model = model.to(DEVICE)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "# Initialize Scaler for Mixed Precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Runs the forward pass in FP16 (half precision)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(input_ids, attention_mask=mask)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, labels)\n",
    "        \n",
    "        # Scales loss and calls backward() to create scaled gradients\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Unscales gradients and calls optimizer.step()\n",
    "        scaler.step(optimizer)\n",
    "        \n",
    "        # Updates the scale for next iteration\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        loop.set_description(f\"Epoch {epoch+1}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "    print(f\"   Avg Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# --- 5. EVALUATE ---\n",
    "print(\"\\n4. Final Evaluation...\")\n",
    "model.eval()\n",
    "preds, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        mask = batch['attention_mask'].to(DEVICE)\n",
    "        outputs = model(input_ids, attention_mask=mask)\n",
    "        _, prediction = torch.max(outputs.logits, dim=1)\n",
    "        preds.extend(prediction.cpu().numpy())\n",
    "        true_labels.extend(batch['labels'].numpy())\n",
    "\n",
    "print(classification_report(true_labels, preds, target_names=classes))\n",
    "\n",
    "# Save\n",
    "if not os.path.exists(SAVE_PATH): os.makedirs(SAVE_PATH)\n",
    "model.save_pretrained(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "np.save(os.path.join(SAVE_PATH, 'classes.npy'), classes)\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf9122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./saved_bert_model_final...\n",
      "âœ… Model loaded on cuda\n",
      "Classes: ['Freelance' 'Full-time' 'Internship']\n",
      "\n",
      "PREDICTION      | CONF.    | TEXT SNIPPET\n",
      "=====================================================================================\n",
      "FULL-TIME       | 99.9% ðŸŸ¢ | \"Staff Accountant managing month-end close processes and general ledger reconciliations.\"\n",
      "FULL-TIME       | 99.9% ðŸŸ¢ | \"Operations Manager overseeing a warehouse facility with 40+ employees.\"\n",
      "FULL-TIME       | 100.0% ðŸŸ¢ | \"DevOps Engineer responsible for CI/CD pipeline automation and AWS infrastructure.\"\n",
      "FULL-TIME       | 99.9% ðŸŸ¢ | \"Marketing Director: Developed and executed go-to-market strategies for Q3 product launch.\"\n",
      "FULL-TIME       | 100.0% ðŸŸ¢ | \"Customer Success Specialist handling tier-2 support tickets and client retention.\"\n",
      "FULL-TIME       | 96.3% ðŸŸ¢ | \"Marketing Intern assisting with social media scheduling and content calendar creation.\"\n",
      "INTERNSHIP      | 100.0% ðŸŸ¢ | \"Clear Tech, Events Intern Sep. 2015 â€“ Aug. 2019Scheduled company meetings with product developersManaged marketing eventsOversaw financial planning for events\"\n",
      "FREELANCE       | 89.1% ðŸŸ¢ | \"Engineering Co-op student rotating through QA, Backend, and Frontend teams.\"\n",
      "INTERNSHIP      | 98.1% ðŸŸ¢ | \"Mountain Rivers, Office Intern Aug. 2019 â€“ CurrentResearch marketing success and raised profits by 30%Create detailed analysis of earnings for company meetingsPrepare detailed reports for distribution at meetingsAnswer phone calls\"\n",
      "INTERNSHIP      | 99.2% ðŸŸ¢ | \"Virtual Intern: Participated in a 4-week remote simulation of investment banking tasks.\"\n",
      "FREELANCE       | 99.7% ðŸŸ¢ | \"Independent Contractor providing translation services for legal documents.\"\n",
      "FREELANCE       | 99.6% ðŸŸ¢ | \"Freelance Web Developer building WordPress sites for local small businesses.\"\n",
      "FULL-TIME       | 99.9% ðŸŸ¢ | \"Consultant: Advised startup founders on seed-stage fundraising strategies.\"\n",
      "FREELANCE       | 100.0% ðŸŸ¢ | \"Self-employed Copywriter creating SEO-optimized blog posts for various clients.\"\n",
      "FULL-TIME       | 99.9% ðŸŸ¢ | \"Gig worker performing task-based deliveries and logistics via mobile platforms.\"\n",
      "FULL-TIME       | 99.8% ðŸŸ¢ | \"Engineering Lead responsible for mentoring 3 summer interns and conducting code reviews.\"\n",
      "FULL-TIME       | 99.7% ðŸŸ¢ | \"Program Coordinator: Organized the company-wide internship orientation and training modules.\"\n",
      "FULL-TIME       | 82.6% ðŸŸ¢ | \"Full-time Implementation Consultant working exclusively for Oracle on client sites.\"\n",
      "FREELANCE       | 99.7% ðŸŸ¢ | \"Internal Strategy Consultant employed permanently by the firm to optimize workflows.\"\n",
      "FULL-TIME       | 98.5% ðŸŸ¢ | \"Acting Interim Lead for the design team during a 3-month summer placement.\"\n",
      "INTERNSHIP      | 57.0% ðŸ”´ | \"Full-stack development intern working 40 hours a week on production code.\"\n",
      "FULL-TIME       | 98.7% ðŸŸ¢ | \"New York, NY | Oct 2020 - Present | Java Developer | Built microservices architecture...\"\n",
      "FULL-TIME       | 84.4% ðŸŸ¢ | \"2019-2022: Graphic Designer. 2022-2023: Art Director. (Multiple roles in one line)\"\n",
      "FREELANCE       | 99.0% ðŸŸ¢ | \"Contractor at Google via TekSystems (converted to FTE after 6 months).\"\n",
      "FULL-TIME       | 99.9% ðŸŸ¢ | \"Temporary Staff handling seasonal overflow in the customer service department.\"\n",
      "INTERNSHIP      | 99.9% ðŸŸ¢ | \"Junior Associate (Summer Program) - Rotational desk work.\"\n",
      "FULL-TIME       | 100.0% ðŸŸ¢ | \"Junior SysAdmin - Permanent role handling night-shift server maintenance.\"\n",
      "FULL-TIME       | 99.5% ðŸŸ¢ | \"Worked as a Java Developer for 3 months.\"\n",
      "FREELANCE       | 98.0% ðŸŸ¢ | \"Freelance Java Developer for 3 months.\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Ensure this matches the SAVE_PATH used in the training step\n",
    "MODEL_PATH = \"./saved_bert_model_final\"\n",
    "MAX_LEN = 128\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_model():\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"âŒ Error: Model not found at {MODEL_PATH}. Run the training cell first.\")\n",
    "        return None, None, None\n",
    "\n",
    "    print(f\"Loading model from {MODEL_PATH}...\")\n",
    "    \n",
    "    # Load Model & Tokenizer\n",
    "    model = BertForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "    tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "    model.to(DEVICE)\n",
    "    model.eval() # Set to evaluation mode\n",
    "    \n",
    "    # Load Class Names\n",
    "    classes_file = os.path.join(MODEL_PATH, 'classes.npy')\n",
    "    if os.path.exists(classes_file):\n",
    "        classes = np.load(classes_file, allow_pickle=True)\n",
    "    else:\n",
    "        # Fallback defaults if file missing\n",
    "        classes = np.array(['Freelance', 'Full-time', 'Internship'])\n",
    "        \n",
    "    print(f\"âœ… Model loaded on {DEVICE}\")\n",
    "    print(f\"Classes: {classes}\\n\")\n",
    "    return model, tokenizer, classes\n",
    "\n",
    "def predict_text(text, model, tokenizer, classes):\n",
    "    if not text: return \"Empty\", 0.0\n",
    "\n",
    "    # 1. Tokenize\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    # 2. Move to GPU\n",
    "    input_ids = encoding['input_ids'].to(DEVICE)\n",
    "    attention_mask = encoding['attention_mask'].to(DEVICE)\n",
    "\n",
    "    # 3. Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "    # 4. Decode\n",
    "    conf, idx = torch.max(probs, dim=1)\n",
    "    return classes[idx.item()], conf.item()\n",
    "\n",
    "# ==========================================\n",
    "# MAIN TEST EXECUTION\n",
    "# ==========================================\n",
    "model, tokenizer, classes = load_model()\n",
    "\n",
    "if model:\n",
    "    # Test cases covering all 3 categories + tricky ones\n",
    "    test_cases = [\n",
    "    # --- Full-time (Clear) ---\n",
    "    \"Staff Accountant managing month-end close processes and general ledger reconciliations.\",\n",
    "    \"Operations Manager overseeing a warehouse facility with 40+ employees.\",\n",
    "    \"DevOps Engineer responsible for CI/CD pipeline automation and AWS infrastructure.\",\n",
    "    \"Marketing Director: Developed and executed go-to-market strategies for Q3 product launch.\",\n",
    "    \"Customer Success Specialist handling tier-2 support tickets and client retention.\",\n",
    "\n",
    "    # --- Internship (Clear) ---\n",
    "    \"Marketing Intern assisting with social media scheduling and content calendar creation.\",\n",
    "    \"Clear Tech, Events Intern Sep. 2015 â€“ Aug. 2019Scheduled company meetings with product developersManaged marketing eventsOversaw financial planning for events\",\n",
    "    \"Engineering Co-op student rotating through QA, Backend, and Frontend teams.\",\n",
    "    \"Mountain Rivers, Office Intern Aug. 2019 â€“ CurrentResearch marketing success and raised profits by 30%Create detailed analysis of earnings for company meetingsPrepare detailed reports for distribution at meetingsAnswer phone calls\",\n",
    "    \"Virtual Intern: Participated in a 4-week remote simulation of investment banking tasks.\",\n",
    "\n",
    "    # --- Freelance (Clear) ---\n",
    "    \"Independent Contractor providing translation services for legal documents.\",\n",
    "    \"Freelance Web Developer building WordPress sites for local small businesses.\",\n",
    "    \"Consultant: Advised startup founders on seed-stage fundraising strategies.\",\n",
    "    \"Self-employed Copywriter creating SEO-optimized blog posts for various clients.\",\n",
    "    \"Gig worker performing task-based deliveries and logistics via mobile platforms.\",\n",
    "\n",
    "    # --- Tricky / Ambiguous (Adversarial & Edge Cases) ---\n",
    "    \n",
    "    # 1. False \"Intern\" Positive (Role is Manager, but mentions interns)\n",
    "    \"Engineering Lead responsible for mentoring 3 summer interns and conducting code reviews.\",\n",
    "    \"Program Coordinator: Organized the company-wide internship orientation and training modules.\",\n",
    "\n",
    "    # 2. False \"Freelance\" Positive (Full-time role with 'consultant' title)\n",
    "    \"Full-time Implementation Consultant working exclusively for Oracle on client sites.\",\n",
    "    \"Internal Strategy Consultant employed permanently by the firm to optimize workflows.\",\n",
    "\n",
    "    # 3. False \"Full-time\" Positive (Internship with heavy responsibility)\n",
    "    \"Acting Interim Lead for the design team during a 3-month summer placement.\",\n",
    "    \"Full-stack development intern working 40 hours a week on production code.\",\n",
    "\n",
    "    # 4. Parsing Noise (Dates and Locations blended in)\n",
    "    \"New York, NY | Oct 2020 - Present | Java Developer | Built microservices architecture...\",\n",
    "    \"2019-2022: Graphic Designer. 2022-2023: Art Director. (Multiple roles in one line)\",\n",
    "\n",
    "    # 5. Contract-to-Hire / Staffing Agencies (The Grey Area)\n",
    "    \"Contractor at Google via TekSystems (converted to FTE after 6 months).\",\n",
    "    \"Temporary Staff handling seasonal overflow in the customer service department.\",\n",
    "\n",
    "    # 6. \"Junior\" Ambiguity (Is it an intern or a fresh grad?)\n",
    "    \"Junior Associate (Summer Program) - Rotational desk work.\",\n",
    "    \"Junior SysAdmin - Permanent role handling night-shift server maintenance.\",\n",
    "    \n",
    "    \"Worked as a Java Developer for 3 months.\",\n",
    "    \"Freelance Java Developer for 3 months.\"\n",
    "]\n",
    "    print(f\"{'PREDICTION':<15} | {'CONF.':<8} | {'TEXT SNIPPET'}\")\n",
    "    print(\"=\"*85)\n",
    "\n",
    "    for text in test_cases:\n",
    "        label, score = predict_text(text, model, tokenizer, classes)\n",
    "        \n",
    "        # Visual Indicator: Green for high confidence, Red for low\n",
    "        indicator = \"ðŸŸ¢\" if score > 0.8 else \"ðŸ”´\"\n",
    "        \n",
    "        print(f\"{label.upper():<15} | {score*100:.1f}% {indicator} | \\\"{text}\\\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
